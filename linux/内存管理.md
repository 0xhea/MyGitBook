# 内存管理

## To-Do

[内存管理机制，Linux/Android内存管理](https://www.jianshu.com/p/2b11639905ec)

分页和分段

内存映射

[linux内存源码分析 - 伙伴系统(初始化和申请页框)](https://www.cnblogs.com/tolimit/p/4610974.html)

[linux内存源码分析 - 内存回收(整体流程)](https://www.cnblogs.com/tolimit/p/5435068.html)

#### 内存管理总结

[深入理解Linux内存管理-之-目录导航](https://blog.csdn.net/gatieme/article/details/52384965)

[内存管理（一）node & zone](http://blog.chinaunix.net/uid-30282771-id-5171166.html)

[内核必须懂(五): per-CPU变量](https://www.jianshu.com/p/f67517b3a150)

***



## 结构

### 内存节点 Node

> [内存管理（一）node & zone](http://blog.chinaunix.net/uid-30282771-id-5171166.html)

​		每个CPU都有自己的本地内存节点（memory node），而且还可以通过QPI总线访问其他CPU下挂的内存节点，只是访问本地内存要比访问其他CPU下的内存的速度高许多，一般经过一次QPI要增加30%的访问时延。



### 内存域 Zone

**查看zone信息：`cat /proc/zoneinfo`**

​		 由于一些特殊的应用场景，导致只能分配特定地址范围内的内存（比如老式的ISA设备DMA时只能使用前16M内存；比如kmalloc只能分配低端内存，而不能分配高端内存），因此在node中又将内存细分为zone。

* **ZONE_DMA**：定义适合DMA的内存域，该区域的长度依赖于处理器类型。比如ARM所有地址都可以进行DMA，所以该值可以很大，或者干脆不定义DMA类型的内存域。而在IA-32的处理器上，一般定义为16M。
* **ZONE_DMA32**：只在64位系统上有效，为一些32位外设DMA时分配内存。如果物理内存大于4G，该值为4G，否则与实际的物理内存大小相同。
* **ZONE_NORMAL**：定义可直接映射到内核空间的普通内存域。在64位系统上，如果物理内存小于4G，该内存域为空。而在32位系统上，该值最大为896M。
* **ZONE_HIGHMEM**：只在32位系统上有效，标记超过896M范围的内存。在64位系统上，由于地址空间巨大，超过4G的内存都分布在ZONE_NORMA内存域。
* **ZONE_MOVABLE**：伪内存域，为了实现减小内存碎片的机制。



### 页 Page

> [内存管理（二）struct page](http://blog.chinaunix.net/uid-30282771-id-5176971.html)

​		因为内核会为每一个物理页帧创建一个struct page的结构体，因此要保证page结构体足够的小，否则仅struct page就要占用大量的内存。出于节省内存的考虑，struct page中使用了大量的联合体union。
​		**内核会为每一个物理页帧创建一个struct page的结构体。**

​		`_count`和`_mapcount`，`_mapcount`表示的是映射次数，而`_count`表示的是使用次数；**被映射了不一定在使用，但要使用必须先映射。**

#### 页、页框、页表

> [linux-----页、页表、页框(块)](https://blog.csdn.net/displayMessage/article/details/80905810)

##### 页

​		将虚拟地址以4K为一个单位分为页，并从0开始依次对每一个页编号。

##### 页框

​		在物理地址以4K为一个单位分为页框，也是从0开始依次编号。

##### 页表

​		操作系统维护的一张记录了每一对页和页框的映射关系表，就是页表。页表被放在物理内存中，由操作系统维护。每个进程都有页表，页表起始地址和页表长度的信息在进程不被CPU执行的时候，存放在其PCB内。



## 反碎片化

> [内存管理（三）内存的反碎片技术-伙伴系统&内存分类](http://blog.chinaunix.net/uid-30282771-id-5185451.html)

### 伙伴系统 Buddy

> [内存管理笔记十、buddy伙伴系统](https://blog.csdn.net/XD_hebuters/article/details/79519406)

​		在实际应用中，经常需要分配一组连续的页框，而频繁地申请和释放不同大小的连续页框，必然导致在已分配页框的内存块中分散了许多小块的空闲页框。这样，即使这些页框是空闲的，其他需要分配连续页框的应用也很难得到满足。
​		为了避免出现这种情况，Linux内核中引入了伙伴系统算法(buddy system)。把所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。最大可以申请1024个连续页框，对应4MB大小的连续内存。每个页框块的第一个页框的物理地址是该块大小的整数倍。
​		假设要申请一个256个页框的块，先从256个页框的链表中查找空闲块，如果没有，就去512个页框的链表中找，找到了则将页框块分为2个256个页框的块，一个分配给应用，另外一个移到256个页框的链表中。如果512个页框的链表中仍没有空闲块，继续向1024个页框的链表查找，如果仍然没有，则返回错误。
​		页框块在释放时，会主动将两个连续的页框块合并为一个较大的页框块。

#### alloc_pages(gfp_mask, order)

> [alloc_page分配内存空间--Linux内存管理(十七)](https://blog.csdn.net/gatieme/article/details/52704844)

​		分配2^order页并返回一个struct page的实例，表示分配的内存块的起始页。

##### 调用关系：

```c
alloc_pages(gfp_mask, order)
alloc_pages_node(numa_node_id(), gfp_mask, order)
__alloc_pages_node(nid, gfp_mask, order);
__alloc_pages(gfp_mask, order, nid);
__alloc_pages_nodemask(gfp_mask, order, preferred_nid, NULL);  // 伙伴系统主要实现

numa_mem_id();  // 获取当前CPU对应的结点id
```

#### __alloc_pages_nodemask() 伙伴系统分配核心函数

```c
// 通过标志集和分配阶来判断是否能进行分配。如果可以，则发起实际的分配操作
get_page_from_freelist(alloc_mask, order, alloc_flags, &ac);
// zone水印检查，检查所遍历到的内存域是否有足够的空闲页
zone_watermark_ok(zone, order, mark, ac_classzone_idx(ac), alloc_flags);
// 实际分配page函数
page = rmqueue(ac->preferred_zoneref->zone, zone, order,gfp_mask, alloc_flags, ac->migratetype);
// 如果是单页，则从pcp分配
page = rmqueue_pcplist();
// 不是单页从伙伴系统分配
__rmqueue_smallest(zone, order, migratetype);
// 分配page
page = list_first_entry_or_null(&area->free_list[migratetype], struct page, lru);
// 如果是在更大的order中分配了页面，则把剩余部分链接到其他free_area中。如在512大小的块中分配了128的页，则要将其它的384分成一个256的块和128的块，并分别链接到对应的free_area中
expand(zone, page, order, current_order, area, migratetype);
```

#### __free_pages(page, order)

> [Linux内核--伙伴系统--页释放](https://www.cnblogs.com/savionyin/p/8310737.html)

##### 释放叶框步骤

1. 检查此页是否被其他进程使用(检查页描述符的_count是否为0)。
2. 如果是释放单个页框，则优先把它放回到该CPU的单页框高速缓存链表中，如果该CPU的单页框高速缓存的页框过多，则把该CPU的页框高速缓存中的pcp->batch个页框放回伙伴系统链表中。
3. 如果不是单个页框，则放回伙伴系统。在放回伙伴系统过程中，会与旁边的空闲页框合并，放入更高等级的order链表中，直到不能合成为止，并将这些连续页框放入对应的链表中。

```c
void __free_pages(struct page *page, unsigned int order)
{
	if (put_page_testzero(page)) {  // 检查页框是否还有进程在使用（检查_count变量的值是否为0）
		if (order == 0)
			free_hot_cold_page(page, false);  // 单个页框放回pcp中，设置为热页
		else
			__free_pages_ok(page, order);  // 连续页框放回伙伴系统
	}
}
```

#### __free_one_page() 伙伴系统释放核心函数

> [Linux内核--伙伴系统--页释放](https://www.cnblogs.com/savionyin/p/8310737.html)

​		无论是单个页框的释放，还是连续多个页框的释放，最后都是调用到__free_one_page()函数。

##### 伙伴系统对页框的合并方法

​		往前检查order次方个连续页框是否为空闲页框，再往后检查order次方个连续页框是否为空闲页框，如果其中一者成立，则合并，并order++，继续检查，但是注意，这些页框都必须为同一个管理区，因为伙伴系统是以管理区为单位的。



### pcp

​		pcp是每CPU页框高速缓冲，由数据结构struct per_cpu_pageset描述，包含在内存域struct zone中。内核经常请求和释放单个页框。为了提升系统性能，每个内存管理区定义了一个每CPU页框高速缓存。所有每CPU高速缓存包含一些预先分配的页框，它们被用于满足本地CPU发出的单一内存请求。

​		**在内存管理区中，分配单页使用per-cpu机制，分配多页使用伙伴系统。**

```
struct per_cpu_pages {
	int count;		/* 内存区per-cpu的总数 */
	int high;		/* 定义per-cpu最高值 */
	int batch;		/* 从伙伴系统中添加或者删除的块大小*/

	/* per-cpu数组链表 ，每个内存迁移类型（内存分类）为一个链表，可以防止内存碎片*/
	struct list_head lists[MIGRATE_PCPTYPES];
};
```

#### 冷页 热页

​		实际上这里为每个内存域（zone）和每个CPU提供了两个高速缓存：一个热高速缓存，它存放的页框中所包含的内存很可能就在cpu硬件高速缓冲。还有一个冷高速缓存。这样原因是如果内核或用户态进程在刚分配到页框后就立即想写页框，那么从热高速缓存中获得页框就对系统性能有利。但如果页框将被DMA操作填充，那么从冷高速缓存中获得页框是方便的。在这种情况下，不会涉及到cpu，并且硬件高速缓存的行不会被修改，从冷高速缓冲获得页框为其他类型的内存分配保存了热页框储备。在现在的内核中，pcp冷热缓存是维持在一个链表中的。

​		当一个页被释放时，默认设置为热页，因为该页可能有些地址的数据还处于映射到CPUcache的情况，当该CPU上有进程申请单个页框时，优先把这些热页分配出去，这样能提高cache命中率，提高效率。而实现方法也很简单，如果是热页，则把它加入到CPU页框高速缓存链表的链表头，如果是冷页，则加入到链表尾。



### 内存分类（迁移类型）

Linux中使用的内存按迁移类型大体可分为以下三类：
* 不可移动页（MIGRATE_UNMOVABLE）：在内存中的位置固定，不能移动到其他地方。内核分配的内存都属于这种类型。
* 可移动页（MIGRATE_MOVABLE）：在内存中的位置可随便移动，只要修改其对应的页表即可。用户态应用程序使用的页属于这种类型。
* 可回收页（MIGRATE_RECLAIMABLE）：不能直接移动，但可以删除，因为其内容可从某些源重新生成，如文件映射产生的页。



### slab (分配小块内存)

​		slab是Linux操作系统的一种内存分配机制。其工作是针对一些经常分配并释放的对象，如进程描述符等，这些对象的大小一般比较小，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内存碎片，而且处理速度也太慢。而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。

##### slab分配器有以下三个基本目标：

1. 减少伙伴算法在分配小块连续内存时所产生的内部碎片；
2. 将频繁使用的对象缓存起来，减少分配、初始化和释放对象的时间开销。
3. 通过着色技术调整对象以更好的使用硬件高速缓存；



### lru

> [linux内存源码分析 - 内存回收(lru链表)](https://www.cnblogs.com/tolimit/p/5447448.html)

#### page 结构中的 lru 成员

页处于不同情况时，page 结构体中的 lru 成员加入的链表不同：

* 是一个进程正在使用的页，加入到对应lru链表和lru缓存中
* 如果为空闲页框，并且是空闲块的第一个页，加入到伙伴系统的空闲块链表中(只有空闲块的第一个页需要加入)
* 如果是一个slab的第一个页，则将其加入到slab链表中(比如slab的满slab链表，slub的部分空slab链表)
* 将页隔离时用于加入隔离链表

#### 对 lru 链表的操作

* 将不处于lru链表的新页放入到lru链表中
* 将非活动lru链表中的页移动到非活动lru链表尾部(活动页不需要这样做，后面说明)
* 将处于活动lru链表的页移动到非活动lru链表
* 将处于非活动lru链表的页移动到活动lru链表
* 将页从lru链表中移除

​		可以看到上面的5种操作，并不是完整的一套操作集(比如没有将活动lru链表中的页移动到活动lru链表尾部)，原因是因为**lru链表并不是供于整个系统所有模块使用的，可以说lru链表的出现，就是专门用于进行内存回收，所以这里的操作集只实现了满足于内存回收所需要使用的操作。**

#### lru 缓存

​		当需要修改lru链表时，一定要占有lru_lock这个锁，在多核的硬件环境中，在同时需要对lru链表进行修改时，锁的竞争会非常的频繁，所以内核提供了一个lru缓存的机制，这种机制能够减少锁的竞争频率。其实这种机制非常简单，lru缓存相当于将一些需要相同处理的页集合起来，当达到一定数量时再对它们进行一批次的处理，这样做可以让对锁的需求集中在这个处理的时间点，而没有lru缓存的情况下，则是当一个页需要处理时则立即进行处理，对锁的需求的时间点就会比较离散。
​		除了*对 lru 链表的操作*中最后一项移除操作外，**其他四样操作除非在特殊情况下， 否则都需要依赖于lru缓存**。
​		**大部分在内存回收路径中对lru链表的操作，都不需要用到lru缓存，只有非内存回收路径中需要对页进行lru链表的操作时，才会使用到lru缓存。**

##### 为每个CPU提供五种缓存：

```c
static DEFINE_PER_CPU(struct pagevec, lru_add_pvec);  // 对应对lru链表的操作1
static DEFINE_PER_CPU(struct pagevec, lru_rotate_pvecs);  // 对应对lru链表的操作2
static DEFINE_PER_CPU(struct pagevec, lru_deactivate_file_pvecs); // 对应对lru链表的操作3
static DEFINE_PER_CPU(struct pagevec, lru_lazyfree_pvecs);  //
#ifdef CONFIG_SMP
static DEFINE_PER_CPU(struct pagevec, activate_page_pvecs);  // 对应对lru链表的操作4
#endif
```

#### lru 链表扫描

​		**lru链表的扫描只有在内存回收时进行**，对于匿名页lru链表和文件页lru链表，在非活动链表长度不足的时候，才会从尾向头去扫描活动lru链表，将部分活动lru链表的页移动非活动lru链表中，对于不同类型的页，内核有不同的判断标准和处理方式。可以说，这个最近最少使用页链表，我个人认为更明确的叫法应该算是**内存回收时最近最少使用页链表**。



## Other

### 内存分配掩码 gfp_mask

> [内存管理（四）内存分配掩码（gfp_mask） - 内存域修饰符 & 内存分配标志](http://blog.chinaunix.net/uid-30282771-id-5191401.html)

​		内存分配掩码包括两部分，内存域修饰符（占低4位）和内存分配标志（从第5位开始）



### memcg

memcg是Linux内核中用于管理cgroup中kernel 内存的模块，整个生命周期应该是跟随cgroup的



### per-CPU变量

> [per-CPU变量](https://www.cnblogs.com/linhaostudy/p/10342667.html)

​		per-CPU变量是linux系统一个非常有趣的特性，它为系统中的每个处理器都分配了该变量的副本。这样做的好处是，在多处理器系统中，当处理器操作属于它的变量副本时，不需要考虑与其他处理器的竞争的问题，同时该副本还可以充分利用处理器本地的硬件缓冲cache来提供访问速度。

​		per-CPU按照存储变量的空间来源分为静态per-CPU变量和动态per-CPU变量，前者的存储空间是在代码编译时静态分配的，而后者的存储空间则是在代码的执行期间动态分配的。

##### 定义per-CPU变量

`DEFINE_PER_CPU(type, name)` 定义类型为type名为name的变量

##### 使用per-CPU变量

`get_cpu_var(name)` 获取名为name的变量

#### cached地址和uncached地址的区别

> [cached地址和uncached地址的区别](https://blog.csdn.net/linuxandroidwince/article/details/7638318)



### UMA NUMA

[Linux内核学习笔记：SMP、UMA、NUMA](https://blog.csdn.net/tiangwan2011/article/details/7298785)



### kmalloc kzalloc vmalloc

[Linux内核空间内存申请函数kmalloc、kzalloc、vmalloc的区别](https://blog.csdn.net/lu_embedded/article/details/51588902)

